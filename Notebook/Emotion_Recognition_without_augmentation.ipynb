{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import csv, zipfile, cv2, os, matplotlib.pyplot as plt, numpy as np, pandas as pd, torch, torch.nn as nn\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from copy import deepcopy\n",
        "from torchvision import models\n"
      ],
      "metadata": {
        "id": "0ysJVtObo1Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bjXVlgwT_w7G"
      },
      "outputs": [],
      "source": [
        "# Extracting Data\n",
        "with zipfile.ZipFile('images.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('Data')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NiwpMm0D_wyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0f6ec79-b934-423a-eb78-d7df6fff3e9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neutral: 4982 images\n",
            "angry: 3993 images\n",
            "surprise: 3205 images\n",
            "happy: 7164 images\n",
            "disgust: 436 images\n",
            "sad: 4938 images\n",
            "fear: 4103 images\n"
          ]
        }
      ],
      "source": [
        "# Counting data\n",
        "base_path = '/content/Data/images/train'\n",
        "image_counts = {}\n",
        "for emotion_folder in os.listdir(base_path):\n",
        "    folder_path = os.path.join(base_path, emotion_folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
        "        image_counts[emotion_folder] = count\n",
        "\n",
        "for emotion, count in image_counts.items():\n",
        "    print(f\"{emotion}: {count} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_array=cv2.imread(\"/content/Data/images/train/angry/11315.jpg\")"
      ],
      "metadata": {
        "id": "O12R4ml2oh4E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "4GSFkmDwoxOu",
        "outputId": "9e439025-3dc7-4c40-bc50-85a542b62c1f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb7a539a5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BMbnDQjo405",
        "outputId": "da9e9805-d852-4d85-bc8b-f6bf289c0886"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48, 48, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "axH65W-xqx8Z"
      },
      "outputs": [],
      "source": [
        "#creating .npy file for training data\n",
        "\n",
        "source_dir = \"/content/Data/images/train\"\n",
        "save_dir = \"/content/Data/images/norm_train\"\n",
        "\n",
        "for emotion in os.listdir(source_dir):\n",
        "    emotion_folder = os.path.join(source_dir, emotion)\n",
        "    save_emotion_folder = os.path.join(save_dir, emotion)\n",
        "\n",
        "    if os.path.isdir(emotion_folder):\n",
        "        os.makedirs(save_emotion_folder, exist_ok=True)\n",
        "\n",
        "        for file in os.listdir(emotion_folder):\n",
        "            file_path = os.path.join(emotion_folder, file)\n",
        "            file_name, _ = os.path.splitext(file)\n",
        "            save_path = os.path.join(save_emotion_folder, file_name + \".npy\")\n",
        "\n",
        "            try:\n",
        "                with Image.open(file_path) as img:\n",
        "                    img = img.convert(\"RGB\")\n",
        "                    img = img.resize((224, 224))\n",
        "                    pixels = np.array(img, dtype=np.float32) / 255.0\n",
        "                    pixels = np.transpose(pixels, (2, 0, 1))\n",
        "                    np.save(save_path, pixels)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file_path}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBsQIpn67Wox",
        "outputId": "f4cd5eb7-aeef-48c8-842e-5d95b737d804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Mapping: {np.str_('angry'): np.int64(0), np.str_('disgust'): np.int64(1), np.str_('fear'): np.int64(2), np.str_('happy'): np.int64(3), np.str_('neutral'): np.int64(4), np.str_('sad'): np.int64(5), np.str_('surprise'): np.int64(6)}\n",
            "CSV saved at: /content/Data/images/norm_train/train.csv\n"
          ]
        }
      ],
      "source": [
        "# creating .csv file for training data\n",
        "\n",
        "root_dir = \"/content/Data/images/norm_train\"\n",
        "csv_path = os.path.join(root_dir, \"train.csv\")\n",
        "\n",
        "# Get all emotion folder names (labels)\n",
        "emotions = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
        "\n",
        "# Step 2: Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(emotions)\n",
        "\n",
        "# print label mapping\n",
        "label_map = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "print(\"Label Mapping:\", label_map)\n",
        "\n",
        "# Write CSV\n",
        "with open(csv_path, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['path', 'label'])\n",
        "\n",
        "    for emotion in emotions:\n",
        "        emotion_dir = os.path.join(root_dir, emotion)\n",
        "        label = label_encoder.transform([emotion])[0]\n",
        "\n",
        "        for filename in os.listdir(emotion_dir):\n",
        "            if filename.endswith(\".npy\"):\n",
        "                rel_path = os.path.join(emotion, filename)\n",
        "                writer.writerow([rel_path, label])\n",
        "\n",
        "print(f\"CSV saved at: {csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y43m8M69CmSX"
      },
      "outputs": [],
      "source": [
        "#creating .npy file for validation data\n",
        "source_dir = \"/content/Data/images/validation\"\n",
        "save_dir = \"/content/Data/images/norm_validation\"\n",
        "\n",
        "for emotion in os.listdir(source_dir):\n",
        "    emotion_folder = os.path.join(source_dir, emotion)\n",
        "    save_emotion_folder = os.path.join(save_dir, emotion)\n",
        "\n",
        "    if os.path.isdir(emotion_folder):\n",
        "        os.makedirs(save_emotion_folder, exist_ok=True)\n",
        "\n",
        "        for file in os.listdir(emotion_folder):\n",
        "            file_path = os.path.join(emotion_folder, file)\n",
        "            file_name, _ = os.path.splitext(file)\n",
        "            save_path = os.path.join(save_emotion_folder, file_name + \".npy\")\n",
        "\n",
        "            try:\n",
        "                with Image.open(file_path) as img:\n",
        "                    img = img.convert(\"RGB\")\n",
        "                    img = img.resize((224, 224))\n",
        "                    pixels = np.array(img, dtype=np.float32) / 255.0\n",
        "                    pixels = np.transpose(pixels, (2, 0, 1))\n",
        "                    np.save(save_path, pixels)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file_path}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c6kzOzVDCuW",
        "outputId": "99e2f906-742a-4002-9705-0b7379a08bf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Mapping: {np.str_('angry'): np.int64(0), np.str_('disgust'): np.int64(1), np.str_('fear'): np.int64(2), np.str_('happy'): np.int64(3), np.str_('neutral'): np.int64(4), np.str_('sad'): np.int64(5), np.str_('surprise'): np.int64(6)}\n",
            "CSV saved at: /content/Data/images/norm_validation/val.csv\n"
          ]
        }
      ],
      "source": [
        "# Creating .csv file for validation data\n",
        "root_dir = \"/content/Data/images/norm_validation\"\n",
        "csv_path = os.path.join(root_dir, \"val.csv\")\n",
        "\n",
        "# Get all emotion folder names (labels)\n",
        "emotions = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(emotions)\n",
        "\n",
        "# Print label mapping\n",
        "label_map = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "print(\"Label Mapping:\", label_map)\n",
        "\n",
        "# Write CSV\n",
        "with open(csv_path, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['path', 'label'])  # header\n",
        "\n",
        "    for emotion in emotions:\n",
        "        emotion_dir = os.path.join(root_dir, emotion)\n",
        "        label = label_encoder.transform([emotion])[0]\n",
        "\n",
        "        for filename in os.listdir(emotion_dir):\n",
        "            if filename.endswith(\".npy\"):\n",
        "                rel_path = os.path.join(emotion, filename)\n",
        "                writer.writerow([rel_path, label])\n",
        "\n",
        "print(f\"CSV saved at: {csv_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8SoJ5dLDLcc",
        "outputId": "4fe16eea-e1c6-44ae-d82a-7c19321e5641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of files: 28821\n"
          ]
        }
      ],
      "source": [
        "# Count total number of images\n",
        "base_path = \"Data/images/norm_train\"\n",
        "\n",
        "total_files = 0\n",
        "\n",
        "for emotion in os.listdir(base_path):\n",
        "    emotion_path = os.path.join(base_path, emotion)\n",
        "    if os.path.isdir(emotion_path):\n",
        "        files = [f for f in os.listdir(emotion_path) if os.path.isfile(os.path.join(emotion_path, f))]\n",
        "        total_files += len(files)\n",
        "\n",
        "print(f\"Total number of files: {total_files}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QK4nGVjpBaoc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.root_dir, self.data.iloc[idx, 0])\n",
        "        label = int(self.data.iloc[idx, 1])\n",
        "        image = np.load(img_path)\n",
        "        image = torch.tensor(image, dtype=torch.float32)\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "z4jElm42Cc3_"
      },
      "outputs": [],
      "source": [
        "train_dataset = EmotionDataset(\"/content/Data/images/norm_train/train.csv\", \"/content/Data/images/norm_train\")\n",
        "val_dataset = EmotionDataset(\"/content/Data/images/norm_validation/val.csv\", \"/content/Data/images/norm_validation\")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I777wpxhsSlk"
      },
      "outputs": [],
      "source": [
        "#Mobilenetv2\n",
        "# class EmotionMobileNetV2(nn.Module):\n",
        "#     def __init__(self, num_classes=7):\n",
        "#         super(EmotionMobileNetV2, self).__init__()\n",
        "\n",
        "#         # Load pretrained MobileNetV2\n",
        "#         self.base_model = models.mobilenet_v2(pretrained=True)\n",
        "\n",
        "#         # Freeze all layers initially\n",
        "#         for param in self.base_model.features.parameters():\n",
        "#             param.requires_grad = False\n",
        "\n",
        "#         # Remove original classifier\n",
        "#         self.base_model.classifier = nn.Identity()\n",
        "\n",
        "#         # Custom classification head with Dropout\n",
        "#         self.custom_classifier = nn.Sequential(\n",
        "#             nn.Linear(1280, 128),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.3),\n",
        "#             nn.Linear(128, 64),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.3),\n",
        "#             nn.Linear(64, num_classes)       # No softmax needed\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.base_model(x)\n",
        "#         x = self.custom_classifier(x)\n",
        "#         return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "E0C9a4U7u5hf"
      },
      "outputs": [],
      "source": [
        "class EmotionEfficientNetB0(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(EmotionEfficientNetB0, self).__init__()\n",
        "\n",
        "        # Load pretrained EfficientNet-B0\n",
        "        self.base_model = models.efficientnet_b0(pretrained=True)\n",
        "\n",
        "\n",
        "        for param in self.base_model.features.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "\n",
        "        self.base_model.classifier = nn.Identity()\n",
        "\n",
        "        self.custom_classifier = nn.Sequential(\n",
        "            nn.Linear(1280, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model(x)\n",
        "        x = self.custom_classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "hs-_LOVLwGmZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "targets = [label for _, label in train_dataset]\n",
        "\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(targets), y=targets)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n"
      ],
      "metadata": {
        "id": "lPRVKQaeq5SG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "q19ZQ5PLEh9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8cf3a79-ce9a-4359-c410-4a0f68de61c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 160MB/s]\n"
          ]
        }
      ],
      "source": [
        "model=EmotionEfficientNetB0(num_classes=7).to(device)\n",
        "# #criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=5e-4)\n",
        "\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "#     optimizer, mode='min', patience=3, factor=0.5, verbose=True\n",
        "# )\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=25)\n",
        "\n",
        "best_acc = 0\n",
        "early_stop_counter = 0\n",
        "history = {\"train_acc\": [], \"val_acc\": [], \"train_loss\": [], \"val_loss\": []}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, input_size=(3, 224, 224))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH9q9osI_tPe",
        "outputId": "147a2e4a-d9e0-4354-dfed-e649bebeb862"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 112, 112]             864\n",
            "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
            "              SiLU-3         [-1, 32, 112, 112]               0\n",
            "            Conv2d-4         [-1, 32, 112, 112]             288\n",
            "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
            "              SiLU-6         [-1, 32, 112, 112]               0\n",
            " AdaptiveAvgPool2d-7             [-1, 32, 1, 1]               0\n",
            "            Conv2d-8              [-1, 8, 1, 1]             264\n",
            "              SiLU-9              [-1, 8, 1, 1]               0\n",
            "           Conv2d-10             [-1, 32, 1, 1]             288\n",
            "          Sigmoid-11             [-1, 32, 1, 1]               0\n",
            "SqueezeExcitation-12         [-1, 32, 112, 112]               0\n",
            "           Conv2d-13         [-1, 16, 112, 112]             512\n",
            "      BatchNorm2d-14         [-1, 16, 112, 112]              32\n",
            "           MBConv-15         [-1, 16, 112, 112]               0\n",
            "           Conv2d-16         [-1, 96, 112, 112]           1,536\n",
            "      BatchNorm2d-17         [-1, 96, 112, 112]             192\n",
            "             SiLU-18         [-1, 96, 112, 112]               0\n",
            "           Conv2d-19           [-1, 96, 56, 56]             864\n",
            "      BatchNorm2d-20           [-1, 96, 56, 56]             192\n",
            "             SiLU-21           [-1, 96, 56, 56]               0\n",
            "AdaptiveAvgPool2d-22             [-1, 96, 1, 1]               0\n",
            "           Conv2d-23              [-1, 4, 1, 1]             388\n",
            "             SiLU-24              [-1, 4, 1, 1]               0\n",
            "           Conv2d-25             [-1, 96, 1, 1]             480\n",
            "          Sigmoid-26             [-1, 96, 1, 1]               0\n",
            "SqueezeExcitation-27           [-1, 96, 56, 56]               0\n",
            "           Conv2d-28           [-1, 24, 56, 56]           2,304\n",
            "      BatchNorm2d-29           [-1, 24, 56, 56]              48\n",
            "           MBConv-30           [-1, 24, 56, 56]               0\n",
            "           Conv2d-31          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-32          [-1, 144, 56, 56]             288\n",
            "             SiLU-33          [-1, 144, 56, 56]               0\n",
            "           Conv2d-34          [-1, 144, 56, 56]           1,296\n",
            "      BatchNorm2d-35          [-1, 144, 56, 56]             288\n",
            "             SiLU-36          [-1, 144, 56, 56]               0\n",
            "AdaptiveAvgPool2d-37            [-1, 144, 1, 1]               0\n",
            "           Conv2d-38              [-1, 6, 1, 1]             870\n",
            "             SiLU-39              [-1, 6, 1, 1]               0\n",
            "           Conv2d-40            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-41            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-42          [-1, 144, 56, 56]               0\n",
            "           Conv2d-43           [-1, 24, 56, 56]           3,456\n",
            "      BatchNorm2d-44           [-1, 24, 56, 56]              48\n",
            "  StochasticDepth-45           [-1, 24, 56, 56]               0\n",
            "           MBConv-46           [-1, 24, 56, 56]               0\n",
            "           Conv2d-47          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-48          [-1, 144, 56, 56]             288\n",
            "             SiLU-49          [-1, 144, 56, 56]               0\n",
            "           Conv2d-50          [-1, 144, 28, 28]           3,600\n",
            "      BatchNorm2d-51          [-1, 144, 28, 28]             288\n",
            "             SiLU-52          [-1, 144, 28, 28]               0\n",
            "AdaptiveAvgPool2d-53            [-1, 144, 1, 1]               0\n",
            "           Conv2d-54              [-1, 6, 1, 1]             870\n",
            "             SiLU-55              [-1, 6, 1, 1]               0\n",
            "           Conv2d-56            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-57            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-58          [-1, 144, 28, 28]               0\n",
            "           Conv2d-59           [-1, 40, 28, 28]           5,760\n",
            "      BatchNorm2d-60           [-1, 40, 28, 28]              80\n",
            "           MBConv-61           [-1, 40, 28, 28]               0\n",
            "           Conv2d-62          [-1, 240, 28, 28]           9,600\n",
            "      BatchNorm2d-63          [-1, 240, 28, 28]             480\n",
            "             SiLU-64          [-1, 240, 28, 28]               0\n",
            "           Conv2d-65          [-1, 240, 28, 28]           6,000\n",
            "      BatchNorm2d-66          [-1, 240, 28, 28]             480\n",
            "             SiLU-67          [-1, 240, 28, 28]               0\n",
            "AdaptiveAvgPool2d-68            [-1, 240, 1, 1]               0\n",
            "           Conv2d-69             [-1, 10, 1, 1]           2,410\n",
            "             SiLU-70             [-1, 10, 1, 1]               0\n",
            "           Conv2d-71            [-1, 240, 1, 1]           2,640\n",
            "          Sigmoid-72            [-1, 240, 1, 1]               0\n",
            "SqueezeExcitation-73          [-1, 240, 28, 28]               0\n",
            "           Conv2d-74           [-1, 40, 28, 28]           9,600\n",
            "      BatchNorm2d-75           [-1, 40, 28, 28]              80\n",
            "  StochasticDepth-76           [-1, 40, 28, 28]               0\n",
            "           MBConv-77           [-1, 40, 28, 28]               0\n",
            "           Conv2d-78          [-1, 240, 28, 28]           9,600\n",
            "      BatchNorm2d-79          [-1, 240, 28, 28]             480\n",
            "             SiLU-80          [-1, 240, 28, 28]               0\n",
            "           Conv2d-81          [-1, 240, 14, 14]           2,160\n",
            "      BatchNorm2d-82          [-1, 240, 14, 14]             480\n",
            "             SiLU-83          [-1, 240, 14, 14]               0\n",
            "AdaptiveAvgPool2d-84            [-1, 240, 1, 1]               0\n",
            "           Conv2d-85             [-1, 10, 1, 1]           2,410\n",
            "             SiLU-86             [-1, 10, 1, 1]               0\n",
            "           Conv2d-87            [-1, 240, 1, 1]           2,640\n",
            "          Sigmoid-88            [-1, 240, 1, 1]               0\n",
            "SqueezeExcitation-89          [-1, 240, 14, 14]               0\n",
            "           Conv2d-90           [-1, 80, 14, 14]          19,200\n",
            "      BatchNorm2d-91           [-1, 80, 14, 14]             160\n",
            "           MBConv-92           [-1, 80, 14, 14]               0\n",
            "           Conv2d-93          [-1, 480, 14, 14]          38,400\n",
            "      BatchNorm2d-94          [-1, 480, 14, 14]             960\n",
            "             SiLU-95          [-1, 480, 14, 14]               0\n",
            "           Conv2d-96          [-1, 480, 14, 14]           4,320\n",
            "      BatchNorm2d-97          [-1, 480, 14, 14]             960\n",
            "             SiLU-98          [-1, 480, 14, 14]               0\n",
            "AdaptiveAvgPool2d-99            [-1, 480, 1, 1]               0\n",
            "          Conv2d-100             [-1, 20, 1, 1]           9,620\n",
            "            SiLU-101             [-1, 20, 1, 1]               0\n",
            "          Conv2d-102            [-1, 480, 1, 1]          10,080\n",
            "         Sigmoid-103            [-1, 480, 1, 1]               0\n",
            "SqueezeExcitation-104          [-1, 480, 14, 14]               0\n",
            "          Conv2d-105           [-1, 80, 14, 14]          38,400\n",
            "     BatchNorm2d-106           [-1, 80, 14, 14]             160\n",
            " StochasticDepth-107           [-1, 80, 14, 14]               0\n",
            "          MBConv-108           [-1, 80, 14, 14]               0\n",
            "          Conv2d-109          [-1, 480, 14, 14]          38,400\n",
            "     BatchNorm2d-110          [-1, 480, 14, 14]             960\n",
            "            SiLU-111          [-1, 480, 14, 14]               0\n",
            "          Conv2d-112          [-1, 480, 14, 14]           4,320\n",
            "     BatchNorm2d-113          [-1, 480, 14, 14]             960\n",
            "            SiLU-114          [-1, 480, 14, 14]               0\n",
            "AdaptiveAvgPool2d-115            [-1, 480, 1, 1]               0\n",
            "          Conv2d-116             [-1, 20, 1, 1]           9,620\n",
            "            SiLU-117             [-1, 20, 1, 1]               0\n",
            "          Conv2d-118            [-1, 480, 1, 1]          10,080\n",
            "         Sigmoid-119            [-1, 480, 1, 1]               0\n",
            "SqueezeExcitation-120          [-1, 480, 14, 14]               0\n",
            "          Conv2d-121           [-1, 80, 14, 14]          38,400\n",
            "     BatchNorm2d-122           [-1, 80, 14, 14]             160\n",
            " StochasticDepth-123           [-1, 80, 14, 14]               0\n",
            "          MBConv-124           [-1, 80, 14, 14]               0\n",
            "          Conv2d-125          [-1, 480, 14, 14]          38,400\n",
            "     BatchNorm2d-126          [-1, 480, 14, 14]             960\n",
            "            SiLU-127          [-1, 480, 14, 14]               0\n",
            "          Conv2d-128          [-1, 480, 14, 14]          12,000\n",
            "     BatchNorm2d-129          [-1, 480, 14, 14]             960\n",
            "            SiLU-130          [-1, 480, 14, 14]               0\n",
            "AdaptiveAvgPool2d-131            [-1, 480, 1, 1]               0\n",
            "          Conv2d-132             [-1, 20, 1, 1]           9,620\n",
            "            SiLU-133             [-1, 20, 1, 1]               0\n",
            "          Conv2d-134            [-1, 480, 1, 1]          10,080\n",
            "         Sigmoid-135            [-1, 480, 1, 1]               0\n",
            "SqueezeExcitation-136          [-1, 480, 14, 14]               0\n",
            "          Conv2d-137          [-1, 112, 14, 14]          53,760\n",
            "     BatchNorm2d-138          [-1, 112, 14, 14]             224\n",
            "          MBConv-139          [-1, 112, 14, 14]               0\n",
            "          Conv2d-140          [-1, 672, 14, 14]          75,264\n",
            "     BatchNorm2d-141          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-142          [-1, 672, 14, 14]               0\n",
            "          Conv2d-143          [-1, 672, 14, 14]          16,800\n",
            "     BatchNorm2d-144          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-145          [-1, 672, 14, 14]               0\n",
            "AdaptiveAvgPool2d-146            [-1, 672, 1, 1]               0\n",
            "          Conv2d-147             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-148             [-1, 28, 1, 1]               0\n",
            "          Conv2d-149            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-150            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-151          [-1, 672, 14, 14]               0\n",
            "          Conv2d-152          [-1, 112, 14, 14]          75,264\n",
            "     BatchNorm2d-153          [-1, 112, 14, 14]             224\n",
            " StochasticDepth-154          [-1, 112, 14, 14]               0\n",
            "          MBConv-155          [-1, 112, 14, 14]               0\n",
            "          Conv2d-156          [-1, 672, 14, 14]          75,264\n",
            "     BatchNorm2d-157          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-158          [-1, 672, 14, 14]               0\n",
            "          Conv2d-159          [-1, 672, 14, 14]          16,800\n",
            "     BatchNorm2d-160          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-161          [-1, 672, 14, 14]               0\n",
            "AdaptiveAvgPool2d-162            [-1, 672, 1, 1]               0\n",
            "          Conv2d-163             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-164             [-1, 28, 1, 1]               0\n",
            "          Conv2d-165            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-166            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-167          [-1, 672, 14, 14]               0\n",
            "          Conv2d-168          [-1, 112, 14, 14]          75,264\n",
            "     BatchNorm2d-169          [-1, 112, 14, 14]             224\n",
            " StochasticDepth-170          [-1, 112, 14, 14]               0\n",
            "          MBConv-171          [-1, 112, 14, 14]               0\n",
            "          Conv2d-172          [-1, 672, 14, 14]          75,264\n",
            "     BatchNorm2d-173          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-174          [-1, 672, 14, 14]               0\n",
            "          Conv2d-175            [-1, 672, 7, 7]          16,800\n",
            "     BatchNorm2d-176            [-1, 672, 7, 7]           1,344\n",
            "            SiLU-177            [-1, 672, 7, 7]               0\n",
            "AdaptiveAvgPool2d-178            [-1, 672, 1, 1]               0\n",
            "          Conv2d-179             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-180             [-1, 28, 1, 1]               0\n",
            "          Conv2d-181            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-182            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-183            [-1, 672, 7, 7]               0\n",
            "          Conv2d-184            [-1, 192, 7, 7]         129,024\n",
            "     BatchNorm2d-185            [-1, 192, 7, 7]             384\n",
            "          MBConv-186            [-1, 192, 7, 7]               0\n",
            "          Conv2d-187           [-1, 1152, 7, 7]         221,184\n",
            "     BatchNorm2d-188           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-189           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-190           [-1, 1152, 7, 7]          28,800\n",
            "     BatchNorm2d-191           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-192           [-1, 1152, 7, 7]               0\n",
            "AdaptiveAvgPool2d-193           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-194             [-1, 48, 1, 1]          55,344\n",
            "            SiLU-195             [-1, 48, 1, 1]               0\n",
            "          Conv2d-196           [-1, 1152, 1, 1]          56,448\n",
            "         Sigmoid-197           [-1, 1152, 1, 1]               0\n",
            "SqueezeExcitation-198           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-199            [-1, 192, 7, 7]         221,184\n",
            "     BatchNorm2d-200            [-1, 192, 7, 7]             384\n",
            " StochasticDepth-201            [-1, 192, 7, 7]               0\n",
            "          MBConv-202            [-1, 192, 7, 7]               0\n",
            "          Conv2d-203           [-1, 1152, 7, 7]         221,184\n",
            "     BatchNorm2d-204           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-205           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-206           [-1, 1152, 7, 7]          28,800\n",
            "     BatchNorm2d-207           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-208           [-1, 1152, 7, 7]               0\n",
            "AdaptiveAvgPool2d-209           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-210             [-1, 48, 1, 1]          55,344\n",
            "            SiLU-211             [-1, 48, 1, 1]               0\n",
            "          Conv2d-212           [-1, 1152, 1, 1]          56,448\n",
            "         Sigmoid-213           [-1, 1152, 1, 1]               0\n",
            "SqueezeExcitation-214           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-215            [-1, 192, 7, 7]         221,184\n",
            "     BatchNorm2d-216            [-1, 192, 7, 7]             384\n",
            " StochasticDepth-217            [-1, 192, 7, 7]               0\n",
            "          MBConv-218            [-1, 192, 7, 7]               0\n",
            "          Conv2d-219           [-1, 1152, 7, 7]         221,184\n",
            "     BatchNorm2d-220           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-221           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-222           [-1, 1152, 7, 7]          28,800\n",
            "     BatchNorm2d-223           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-224           [-1, 1152, 7, 7]               0\n",
            "AdaptiveAvgPool2d-225           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-226             [-1, 48, 1, 1]          55,344\n",
            "            SiLU-227             [-1, 48, 1, 1]               0\n",
            "          Conv2d-228           [-1, 1152, 1, 1]          56,448\n",
            "         Sigmoid-229           [-1, 1152, 1, 1]               0\n",
            "SqueezeExcitation-230           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-231            [-1, 192, 7, 7]         221,184\n",
            "     BatchNorm2d-232            [-1, 192, 7, 7]             384\n",
            " StochasticDepth-233            [-1, 192, 7, 7]               0\n",
            "          MBConv-234            [-1, 192, 7, 7]               0\n",
            "          Conv2d-235           [-1, 1152, 7, 7]         221,184\n",
            "     BatchNorm2d-236           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-237           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-238           [-1, 1152, 7, 7]          10,368\n",
            "     BatchNorm2d-239           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-240           [-1, 1152, 7, 7]               0\n",
            "AdaptiveAvgPool2d-241           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-242             [-1, 48, 1, 1]          55,344\n",
            "            SiLU-243             [-1, 48, 1, 1]               0\n",
            "          Conv2d-244           [-1, 1152, 1, 1]          56,448\n",
            "         Sigmoid-245           [-1, 1152, 1, 1]               0\n",
            "SqueezeExcitation-246           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-247            [-1, 320, 7, 7]         368,640\n",
            "     BatchNorm2d-248            [-1, 320, 7, 7]             640\n",
            "          MBConv-249            [-1, 320, 7, 7]               0\n",
            "          Conv2d-250           [-1, 1280, 7, 7]         409,600\n",
            "     BatchNorm2d-251           [-1, 1280, 7, 7]           2,560\n",
            "            SiLU-252           [-1, 1280, 7, 7]               0\n",
            "AdaptiveAvgPool2d-253           [-1, 1280, 1, 1]               0\n",
            "        Identity-254                 [-1, 1280]               0\n",
            "    EfficientNet-255                 [-1, 1280]               0\n",
            "          Linear-256                  [-1, 128]         163,968\n",
            "            ReLU-257                  [-1, 128]               0\n",
            "         Dropout-258                  [-1, 128]               0\n",
            "          Linear-259                   [-1, 64]           8,256\n",
            "            ReLU-260                   [-1, 64]               0\n",
            "         Dropout-261                   [-1, 64]               0\n",
            "          Linear-262                    [-1, 7]             455\n",
            "================================================================\n",
            "Total params: 4,180,227\n",
            "Trainable params: 172,679\n",
            "Non-trainable params: 4,007,548\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 173.66\n",
            "Params size (MB): 15.95\n",
            "Estimated Total Size (MB): 190.18\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mD9tjG2fEkWv"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss, total_correct = 0, 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "    accuracy = total_correct / len(loader.dataset)\n",
        "    return total_loss / len(loader), accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "TQssCRAWEqZF"
      },
      "outputs": [],
      "source": [
        "def validate_one_epoch(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = running_loss / total\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nB9fJ0cXJuTl"
      },
      "outputs": [],
      "source": [
        "def unfreeze_mobilenet(model):\n",
        "    for param in model.base_model.features[5:].parameters():\n",
        "        param.requires_grad = True\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "patience=3\n",
        "patience_counter=0\n",
        "\n",
        "for epoch in range(1, 51):\n",
        "    if epoch == 10:\n",
        "      unfreeze_mobilenet(model)\n",
        "      print(\"✅ Unfroze last few layers of MobileNetV2\")\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_acc = validate_one_epoch(model, val_loader, criterion)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"Epoch {epoch} | Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "    history[\"train_acc\"].append(train_acc)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "      best_acc = val_acc\n",
        "      patience_counter = 0\n",
        "      torch.save(model.state_dict(), f\"best.pt\")\n",
        "    else:\n",
        "      patience_counter += 1\n",
        "      if patience_counter >= patience:\n",
        "          print(\"Early stopping triggered\")\n",
        "          break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "histories = deepcopy(history)"
      ],
      "metadata": {
        "id": "B37kedJ08GGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f51eefb-d12d-4ece-e194-310c6e42177e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train Acc: 0.2256, Val Acc: 0.3755\n",
            "Epoch 2 | Train Acc: 0.3215, Val Acc: 0.3429\n",
            "Epoch 3 | Train Acc: 0.3571, Val Acc: 0.3965\n",
            "Epoch 4 | Train Acc: 0.3773, Val Acc: 0.4329\n",
            "Epoch 5 | Train Acc: 0.3970, Val Acc: 0.4319\n",
            "Epoch 6 | Train Acc: 0.4106, Val Acc: 0.4232\n",
            "Epoch 7 | Train Acc: 0.4252, Val Acc: 0.4357\n",
            "Epoch 8 | Train Acc: 0.4357, Val Acc: 0.4550\n",
            "Epoch 9 | Train Acc: 0.4422, Val Acc: 0.4498\n",
            "✅ Unfroze last few layers of MobileNetV2\n",
            "Epoch 10 | Train Acc: 0.4777, Val Acc: 0.5327\n",
            "Epoch 11 | Train Acc: 0.5585, Val Acc: 0.5944\n",
            "Epoch 12 | Train Acc: 0.5963, Val Acc: 0.5996\n",
            "Epoch 13 | Train Acc: 0.6155, Val Acc: 0.6131\n",
            "Epoch 14 | Train Acc: 0.6335, Val Acc: 0.6190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EdW4XNVBBub"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(histories['train_acc'], label=f'Train Acc')\n",
        "plt.plot(histories['val_acc'], label=f'Val Acc')\n",
        "plt.title(\"Training vs Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(histories['train_loss'], label=f'Train Loss')\n",
        "plt.plot(histories['val_loss'], label=f'Val Loss')\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NrCCkMe48o64"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}